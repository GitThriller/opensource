{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xlsx2csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pyodbc\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from typing import Union, List\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "import dttlib\n",
    "from importlib import reload\n",
    "reload(dttlib)\n",
    "from dttlib.data.reading import read_data\n",
    "from dttlib.data.uploading import DataFrameUploader\n",
    "\n",
    "import swifter\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "import PyPDF2\n",
    "import tabula\n",
    "import camelot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code viewing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#pd.set_option('display.width', None)\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "#pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path=Path(r'')\n",
    "raw_path=master_path/'2. Original Data'\n",
    "input_path=master_path/'3. Pre-cleaned Data'\n",
    "output_path=master_path/'4. Cleaned data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read delimitered data using dttlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_data(r'',\n",
    "             file_extension='',\n",
    "             header=0,\n",
    "             delimiter='|',\n",
    "             encoding='utf-8',\n",
    "             quoting=csv.QUOTE_NONE,\n",
    "#             error_bad_lines=False,\n",
    "#             engine='python'\n",
    "            )\n",
    "\n",
    "#df.insert(0, 'DTT_ID', range(1, 1 + len(df)))\n",
    "\n",
    "\n",
    "print(df.shape,'\\n')\n",
    "\n",
    "print(df.dtypes,'\\n')\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read delimitered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir=glob(fr'{raw_path}/actt_1/lines/*.actt')\n",
    "list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat([pd.read_csv(f,\n",
    "                          encoding='utf-8',\n",
    "                          sep=',',\n",
    "                          dtype = str,\n",
    "                          header=0,\n",
    "                          index_col=None,\n",
    "                          engine='c',\n",
    "#                         delim_whitespace=True,error_bad_lines=False,engine='python',quoting=csv.QUOTE_NONE\n",
    "                        ) for f in list_dir],ignore_index=True) \n",
    "# if given error: cannot reindex from a duplicate axis, needs to put ignore_index=True\n",
    "\n",
    "print(df.shape,'\\n')\n",
    "\n",
    "print(df.dtypes,'\\n')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read fixed width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files\n",
    "dir=glob(fr'{}/*.txt')\n",
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colspecs = [(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,),(,)]\n",
    "\n",
    "\n",
    "df=pd.concat([pd.read_fwf(fp,dtype=str,index_col=None,header=None,colspecs=colspecs,names=['','',''],\n",
    "#                          skiprows=28,skipfooter=20,\n",
    "                         ).assign(DTT_FILENAME=os.path.basename(fp)) for fp in dir],ignore_index=True) \n",
    "\n",
    "df.insert(0, 'DTT_ID', range(1, 1 + len(df)))\n",
    "\n",
    "#df.insert(1, 'Ledger', df['DTT_FILENAME'].apply(lambda x: x.split('_')[5]).str.replace('.txt','').str.strip())\n",
    "\n",
    "#df=df[(~df['Account'].isnull()) &\\\n",
    "#        (~df['Account'].isin(['Currenc', 'Ledger', 'Account','-------','TOTA','T','\\x0c']))]\n",
    "\n",
    "print(df.shape,'\\n')\n",
    "\n",
    "print(df.dtypes,'\\n')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read fixed width alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_fwf(input_path/'',header=None)\n",
    "\n",
    "print(df.shape,'\\n') \n",
    "\n",
    "print(df.dtypes,'\\n')\n",
    "\n",
    "df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1].str.split('\\t', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [df[col].str.split(pat='\\t', expand=True).add_prefix(col) for col in df.columns]\n",
    "clean_df = pd.concat(splits, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim and remove double quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cols=df.select_dtypes(['object']).columns\n",
    "df[cols]=df[cols].apply(lambda x: x.str.replace('\"','').str.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename NaN columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_axis([,'DTT_FILENAME'],axis='columns',inplace=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union=pd.concat([df,df,df], ignore_index=True)\n",
    "\n",
    "print(df_union.shape,'\\n')\n",
    "\n",
    "print(df_union.dtypes,'\\n')\n",
    "\n",
    "df_union.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_union.to_csv(input_path/'.csv',sep='|',index=False) #quoting=csv.QUOTE_ALL,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join=pd.merge(df,df,how='left',suffixes=('', '_y'),\n",
    "                 left_on=[''],\n",
    "                 right_on=[''])\n",
    "\n",
    "print(df_join.shape,'\\n')\n",
    "\n",
    "print(df_join.dtypes,'\\n')\n",
    "\n",
    "df_join.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_join.to_csv(input_path/'.csv',sep='|',index=False) #quoting=csv.QUOTE_ALL,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to database using dttlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader=DataFrameUploader(server='', database='')\n",
    "uploader.upload(df,table_name='',initials='',pk='DTT_ID',overwrite=True,nvarchar_size='500')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check rowcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['DTT_FILENAME'].value_counts(),'\\n')\n",
    "print('Total row count:',sum(df['DTT_FILENAME'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check analysis period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\n",
    "    'Date ranges from ',\n",
    "    pd.to_datetime(df[''],format='%Y-%m-%d').min(),\n",
    "    ' to ',\n",
    "    pd.to_datetime(df[''],format='%Y-%m-%d').max()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[''],ascending = True)[''].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df[''].isin([''])]\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df['Amount'].isnull()\n",
    "df.loc[mask,'Amount']='0.00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df[''].str.endswith('-')\n",
    "df.loc[mask,'']= '-' + df[''].str.rstrip('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert amount as float\n",
    "df['Amount']=df['Amount'].str.replace(',','').astype('float') * df[''].apply(lambda x: -1 if x =='H' else 1)\n",
    "\n",
    "# breakdowns\n",
    "print('Total S (Debit):',round(df[df['']<0][''].sum(),2),'\\n')\n",
    "print('Total H (Credit):',round(df[df['']>0][''].sum(),2))\n",
    "\n",
    "# check sum\n",
    "print(round(df['Amount'].sum(),2),'\\n')\n",
    "\n",
    "print(round(df.groupby('DTT_FILENAME').agg({'Amount': 'sum'}),2).rename(columns={'Amount':'Sum'}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate movement by gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum by gl based on the raw data\n",
    "sum_by_xx_raw=round(df.groupby('Account Number').agg({'Amount': 'sum'}).rename(columns={'Amount':'Sum'}),2).reset_index()\n",
    "sum_by_xx_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export if needed\n",
    "#sum_by_xx_raw.to_excel(output_path/'sum_by_gl_raw.xlsx',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=df.columns.str.title()\n",
    "df.columns=df.columns.str.upper()\n",
    "df.columns=df.columns.str.lower()\n",
    "df.columns=df.columns.str.replace('','')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean date format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively\n",
    "df['']=pd.to_datetime(df[''],format='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[''].str.contains('31/',na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[''].str[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=df[''].str.contains('31/',na=False)\n",
    "df.loc[mask1,'']='28'+df['RETIREMENT DATE'].str[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[''].str.contains('-30',na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=df[''].str.contains('-30',na=False)\n",
    "df.loc[mask1,'']=df[''].str[:8]+'28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.to_datetime(df['BKPF-BUDAT'],format='%Y%m%d').min(),\n",
    "pd.to_datetime(df['BKPF-BUDAT'],format='%Y%m%d').max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case like '08/07/20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['day','month','year']]=df[''].str.split('/',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_year_length=df['year'].str.len()==2\n",
    "df.loc[mask_year_length,'year'] = '20' + df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']=df['year'].map(str) + '-' + df['month'].map(str) + '-' + df['day'].map(str)\n",
    "df['']=df['Date'].astype('datetime64')\n",
    "df['']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case like '44013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']=dt.datetime(1899, 12, 30) + pd.to_timedelta(df[''].astype(int), 'D')\n",
    "df['']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julian date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']=pd.to_datetime(df[''],format='1%y%j')\n",
    "df['']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']=df[''] + '_' + df[''] + '_' + df[''] + '_' + df['']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=df[''].xxxx\n",
    "df.loc[mask,'']=''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Unique Line Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, '', range(1, 1 + len(df)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename a few columns\n",
    "col_name_raw = ['','','','','','','','','','']\n",
    "\n",
    "col_mapping = {'':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "               '':'',\n",
    "              }\n",
    "\n",
    "col_name_new = list(col_mapping.values())\n",
    "\n",
    "col_name_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_subset=df[col_name_raw].rename(columns=col_mapping)[col_name_new]\n",
    "\n",
    "print(df_subset.shape,'\\n')\n",
    "\n",
    "print(df_subset.dtypes,'\\n')\n",
    "\n",
    "df_subset.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=pd.read_excel(master_path/'JET Column Mappings - SAP.xlsx','Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapping=dict(zip(col['Column to use'],col['InsightBox column name']))\n",
    "\n",
    "col_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create exp tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset dataframe for myA required columns\n",
    "df_subset=df[col_mapping.keys()].rename(columns=col_mapping)\n",
    "\n",
    "print(df_subset.shape,'\\n')\n",
    "\n",
    "print(df_subset.dtypes,'\\n')\n",
    "\n",
    "df_subset.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post validation after cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Date ranges from ',df_subset[''].min(), ' to ', df_subset[''].max())\n",
    "print('Date ranges from ',df_subset[''].min(), ' to ', df_subset[''].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_subset['Amount'].sum(),2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate sum by xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_by_xxx=round(df_subset.groupby('').agg({'':'count','Amount': 'sum'}),2)\n",
    "\n",
    "unbalanced=sum_by_xxx[sum_by_xxx['Amount'].abs()>0].rename(columns={'':'No._of_lines','Amount':'Sum'})\n",
    "\n",
    "unbalanced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate uniqueness between Journal ID and Line Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_unique=df_subset.groupby(['Journal ID','Journal line number']).size()\n",
    "check_unique[check_unique>1].to_frame()#.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate if DocType, Users, DateEffect and DatePosted are unique on Journal ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_jID_doc=df_subset.groupby('Journal ID').agg({'Document Type': lambda w: w.nunique()})\n",
    "unique_jID_doc[unique_jID_doc['Document Type']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_jID_user=df_subset.groupby('Journal ID').agg({'Posting User': lambda x: x.nunique()})\n",
    "unique_jID_user[unique_jID_user['Posting User']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_jID_e_date=df_subset.groupby('Journal ID').agg({'Date Effective': lambda y: y.nunique()})\n",
    "unique_jID_e_date[unique_jID_e_date['Date Effective']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_jID_p_date=df_subset.groupby('Journal ID').agg({'Date Posted': lambda z: z.nunique()})\n",
    "unique_jID_p_date[unique_jID_p_date['Date Posted']>1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check on GL acc format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_subset.sort_values(by=[''], ascending = True)[''].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate movement by gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_by_gl=df_subset.groupby('GL Account').agg({'Journal Line Number': 'count','Amount': 'sum'}\n",
    "                                             ).rename(columns = {'Journal Line Number':'Count','Amount':'Sum'})\n",
    "                                             \n",
    "sum_by_gl['Sum']=round(sum_by_gl['Sum'],2)\n",
    "\n",
    "sum_by_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#sum_by_gl.to_excel(output_path/'movement_by_gl.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export cleaned data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate final tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_subset.drop(columns=['',''])\n",
    "\n",
    "print(df_final.shape,'\\n') # , maintained\n",
    "\n",
    "print(df_final.dtypes,'\\n')\n",
    "\n",
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#df_final.to_csv(output_path/'journal_lines.csv',sep=',',quoting=csv.QUOTE_ALL,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate doc types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_type=df_final.groupby('Document Type').agg({'Journal ID': lambda x: x.nunique(),\n",
    "                                                'Journal Line Number': 'count',\n",
    "                                                'Amount': 'sum'}\n",
    "                                              ).rename(columns = {'Journal ID':'Number of journal IDs',\n",
    "                                                                  'Journal Line Number':'Number of journal lines',\n",
    "                                                                  'Amount':'Total amount'}).reset_index()\n",
    "\n",
    "doc_type['Is standard document type']=0\n",
    "\n",
    "doc_type['Total amount']=round(doc_type['Total amount'],2)\n",
    "\n",
    "doc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#doc_type.to_csv(output_path/'document_types.csv',sep=',',quoting=csv.QUOTE_ALL,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate posting users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posting_user=df_final.groupby('Posting User').agg({'Journal ID': lambda x: x.nunique(),\n",
    "                                                   'Journal Line Number': 'count',\n",
    "                                                   'Amount': 'sum'}\n",
    "                                                 ).rename(columns = {'Journal ID':'Number of journal IDs',\n",
    "                                                                     'Journal Line Number':'Number of journal lines',\n",
    "                                                                     'Amount':'Total amount'}).reset_index()\n",
    "\n",
    "posting_user['Is system entry']=0\n",
    "\n",
    "posting_user['User of interest']=0\n",
    "\n",
    "posting_user['Total amount']=round(posting_user['Total amount'],2)\n",
    "\n",
    "posting_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#posting_user.to_csv(output_path/'posting_user.csv',sep=',',quoting=csv.QUOTE_ALL,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import xxx list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xxx_list=read_data(input_path,file_extension='',encoding='utf-8',delimiter='|',dtype=str,header=0,index_col=None\n",
    "#                      error_bad_lines=False,engine='python',quoting=csv.QUOTE_NONE\n",
    "            )\n",
    "\n",
    "print(df_xxx_list.shape,'\\n') # \n",
    "\n",
    "df_xxx_list.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import xxx list if xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx_list_dir=glob(fr'{}/*.xlsx')\n",
    "xxx_list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xxx_list=pd.concat([pd.read_excel(fp,dtype=str,index_col=None,header=0)\\\n",
    "              .assign(DTT_FILENAME=os.path.abspath(fp)) for fp in xxx_list_dir]) \n",
    "# can use os.path.basename to just get the name of file instead of full path\n",
    "\n",
    "print(df_xxx_list.shape,'\\n') \n",
    "\n",
    "print(df_xxx_list.dtypes,'\\n') \n",
    "\n",
    "df_xxx_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(input_path/'.csv',sep='|',index=False) #quoting=csv.QUOTE_ALL,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract xxx only related journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xxx_only=pd.merge(df_final,df_xxx_list,how='inner',suffixes=('', '_y'),\n",
    "                     left_on=[''],right_on=['']\n",
    "                    )\n",
    "\n",
    "df_xxx_only=df_xxx_only[['','','','']] # or df_xxx_only=df_xxx_only.drop(columns=['',''])\n",
    "\n",
    "print(df_xxx_only.shape,'\\n')\n",
    "\n",
    "print(df_xxx_only.dtypes,'\\n') \n",
    "\n",
    "df_xxx_only.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_xxx_only[(df_xxx_only['']>='') & (df_xxx_only['']<='')].to_csv(output_path/'.csv',quoting=csv.QUOTE_ALL,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_xxx_only[(df_xxx_only['']>='') & (df_xxx_only['']<='')].to_excel(output_path/'.xlsx',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract journals touch xxx account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xxx_unique_jIDs=pd.DataFrame(df_xxx_only['Journal ID'].unique())\n",
    "\n",
    "print(df_xxx_unique_jIDs.shape,'\\n')\n",
    "\n",
    "print(df_xxx_unique_jIDs.dtypes,'\\n')\n",
    "\n",
    "df_xxx_unique_jIDs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xxx_all=pd.merge(df_xxx_unique_jIDs,df_final, how='inner',left_on=[''],right_on=['Journal ID'])\n",
    "\n",
    "df_xxx_all=df_xxx_all[['','','','']] # or df_xxx_all=df_xxx_all.drop(columns=['',''])\n",
    "\n",
    "print(df_xxx_all.shape,'\\n')\n",
    "\n",
    "print(df_xxx_all.dtypes,'\\n')\n",
    "\n",
    "df_xxx_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_xxx_all[(df_xxx_all['']>='') & (df_xxx_all['']<='')].to_csv(output_path/'.csv',quoting=csv.QUOTE_ALL,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_xxx_all[(df_xxx_all['']>='') & (df_xxx_all['']<='')].to_excel(output_path/'.xlsx',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d63edeb0bb6a36ca0e8532a90b8f233bbc40b90417812a1f62a872e672cb7196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
