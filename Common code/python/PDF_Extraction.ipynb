{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract claim value for each vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import PyPDF2\n",
    "from glob import glob\n",
    "\n",
    "claims_path = r''\n",
    "input_path = r''\n",
    "output_path = r''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = pd.read_csv(claims_path)\n",
    "claims['DTT_Claim_Number_Standardised'] = claims['DTT_Claim_Number_Standardised'].apply(str)\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df that has all of the files that have been extracted from first layer extraction\n",
    "file_list = glob(input_path+'\\*.pdf')\n",
    "# for file in file_list\n",
    "files = pd.DataFrame(file_list, columns =['filepath']) \n",
    "files['filepath'] = files['filepath'].astype(str)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match a filepath to its corresponding claim number\n",
    "claims['filepath'] = claims['DTT_Claim_Number_Standardised'].apply(lambda claim: files[files['filepath'].str.contains(claim)]['filepath'].any(0))\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many claim numbers do not have corresponding PDFs\n",
    "missing = claims[claims['filepath'] == False]\n",
    "missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows without corresponding PDF file path\n",
    "claims = claims[claims['filepath'] != False]\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate files for the same claim number\n",
    "duplicates = claims[claims.duplicated(['filepath'])]\n",
    "duplicates #no duplicates in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the claim value from each PDF\n",
    "t0 = time.time()\n",
    "\n",
    "success = []\n",
    "values = []\n",
    "for ind in claims.index:\n",
    "    df = pd.DataFrame()\n",
    "    file = claims['filepath'][ind]\n",
    "    if os.path.exists(file):\n",
    "        s = False\n",
    "        v = 0\n",
    "        try: \n",
    "            tables = camelot.read_pdf(file, flavor='stream', pages='all',encoding = 'ISO-8859-1',table_areas=['0,800,800,00'], strip_text=',$') # ,table_areas=['0,842,595,0']\n",
    "            if len(tables) == 0:\n",
    "                print(file + ' no content read through, extraction not successful')\n",
    "            else:\n",
    "                i = 0\n",
    "                found = False\n",
    "                while (i < len(tables) and found == False):\n",
    "                    df = tables[i].df\n",
    "                    for col in df.columns:\n",
    "                        if not (df[df[col].str.contains('Tax 15.00%')].empty):\n",
    "                            found = True\n",
    "                            print(file.split('\\\\')[-1], \"page using:\", i)\n",
    "                    i += 1\n",
    "                if found == False:\n",
    "                    df = tables[-1].df\n",
    "                \n",
    "                list1 = df.stack().tolist() #convert to list\n",
    "                list2 = [s for s in list1 if \".\" in s] #remove all elements of list not containing decimal\n",
    "                list3 = [s.split() for s in list2] #split random number containing a new line (meant to have been in seperate cells)\n",
    "                list4 = sum(list3, []) #flatten to one list instead of list of lists\n",
    "                list4a = [s for s in list4 if \"%\" not in s] #remove all percentages\n",
    "                list5 = [re.sub('[^0-9.-]', '', s) for s in list4a] #remove every character that isn't a number or a decimal point\n",
    "                list6 = [float(s) for s in list5 if re.match('^-?[0-9]+(\\.[0-9][0-9])$',s)] #remove any item that does not fit [digits].[digit][digit]\n",
    "                list6a = [s for s in list6 if s != 0] #remove all zero elements \n",
    "                list7 = list6a[-3:] #take the last 3 items\n",
    "                list7.sort(key=abs)\n",
    "        #         print(list7, \"sum:\", list7[0]+list7[1], \"w/o GST:\", list7[1], \"w GST:\", list7[2])\n",
    "                if (len(list7) > 2 and round(list7[0]+list7[1], 2) == round(list7[2], 2)):\n",
    "                    s = True\n",
    "                    v = round(list7[1], 2)\n",
    "                else:\n",
    "                    s = False\n",
    "                    v = round(max(list7, key=abs)*10/11, 2)\n",
    "\n",
    "        except ValueError: \n",
    "            print(file, 'Extaction not successful') \n",
    "    else:\n",
    "        print(file, \"Could not be opened\")\n",
    "    success.append(s)\n",
    "    values.append(v)\n",
    "\n",
    "claims['w/o+GST=w'] = success\n",
    "claims['claim w/o GST'] = values\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"total time:\", t1-t0)\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check where the values are negative of themselves\n",
    "discrepency = claims[claims['AMOUNT_IN_DOC_CURR'] != claims['claim w/o GST']]\n",
    "discrepency = discrepency[abs(discrepency['AMOUNT_IN_DOC_CURR']) == abs(discrepency['claim w/o GST'])]\n",
    "discrepency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unopened = claims[claims['claim w/o GST'] == 0]\n",
    "unopened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only looking at files that were able to be opened\n",
    "claims = claims[claims['claim w/o GST'] != 0]\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows where the internal validity check passed\n",
    "passed = claims[claims['w/o+GST=w'] == True]\n",
    "passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows where the three numbers used are not the claim value with and without GST and GST (ie. don't pass the internal check)\n",
    "failed = claims[claims['w/o+GST=w'] == False]\n",
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the new results against the old edc ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all of the output into 1 dataframe\n",
    "file_list = glob(r'')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_lines = [pd.read_csv(f, sep=',', dtype=str, encoding='windows-1252', low_memory=False) for f in file_list]\n",
    "check =pd.concat(check_lines, ignore_index=True)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the claim value obtained from the EDC results with the data frame\n",
    "claims['check'] = claims['DTT_Claim_Number_Standardised'].apply(lambda claim: check[check['Reference No.'].str.contains(claim)]['Claim Amount Excl GST'].any(0))\n",
    "claims['check'] = claims['check'].str.replace(',', '').astype(float)\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider claims for which the new value matches the old value to be a positive\n",
    "positives = claims[claims['claim w/o GST'] == claims['check']]\n",
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider claims for which the new value does not match the old value to be a negative\n",
    "negatives = claims[claims['claim w/o GST'] != claims['check']]\n",
    "negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "fp = claims[claims['claim w/o GST'] != claims['check']]\n",
    "fp = fp[fp['w/o+GST=w'] == True]\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true negatives\n",
    "tn = claims[claims['claim w/o GST'] != claims['check']]\n",
    "tn = tn[tn['w/o+GST=w'] == False]\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true positives\n",
    "tp = claims[claims['claim w/o GST'] == claims['check']]\n",
    "tp = tp[tp['w/o+GST=w'] == True]\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "fn = claims[claims['claim w/o GST'] == claims['check']]\n",
    "fn = fn[fn['w/o+GST=w'] == False]\n",
    "fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims.loc['filename'] = claims['filepath'].str.split('\\\\').str[-1]\n",
    "claims['Year'] = 'FY1920'\n",
    "claims = claims.reset_index()\n",
    "claims.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the expected formatting\n",
    "export_df = claims[['filename', 'DTT_Customer_Standardised', 'DTT_Claim_Number_Standardised', 'claim w/o GST', 'filepath', 'Year', 'w/o+GST=w']]\n",
    "\n",
    "export_df = export_df.rename(columns={\"filename\": \"FileName\",\n",
    "                                      \"DTT_Customer_Standardised\": \"Vendor\", \n",
    "                                      \"DTT_Claim_Number_Standardised\": \"Reference No.\", \n",
    "                                      \"claim w/o GST\": \"Claim Amount\",\n",
    "                                      \"filepath\": \"FilePath\", \n",
    "                                      \"w/o+GST=w\": \"Success\"})\n",
    "# export_df = export_df.reset_index()\n",
    "export_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df.to_csv(output_path+'', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
